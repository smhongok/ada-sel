{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324ddbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastmri\n",
    "from fastmri.data import transforms\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from typing import Dict, NamedTuple, Optional, Sequence, Tuple, Union\n",
    "from fastmri.data.transforms import to_tensor, center_crop, complex_center_crop\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "RECON_SIZE = (320, 320)\n",
    "RSS_RECON_SIZE = (320, 320)\n",
    "NUM_COMPRESSED_COILS = 16 # 4\n",
    "NUM_LIMIT_COILS = 16\n",
    "assert NUM_COMPRESSED_COILS <= NUM_LIMIT_COILS\n",
    "\n",
    "# whole validation dataset\n",
    "\n",
    "SRC = '/mnt/e/nyu_fastmri_brain/multicoil_val/' # directory of NYU fastMRI brain multi-coil validation dataset\n",
    "DST_VAL = '/mnt/e/nyu_fastmri_brain/multibrain_dataset/multicoil_val/' # directory of compressed validation dataset\n",
    "DST_TEST = '/mnt/e/nyu_fastmri_brain/multibrain_dataset/multicoil_test/' # directory of compressed test dataset\n",
    "\n",
    "os.makedirs(DST_VAL, exist_ok=True)\n",
    "os.makedirs(DST_TEST, exist_ok=True)\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_rate = 0.2\n",
    "\n",
    "total_num = 0\n",
    "for file_idx in tqdm(range(len(glob.glob(SRC + 'file*.h5')))):\n",
    "    file_name = glob.glob(SRC + 'file*.h5')[file_idx]\n",
    "    with h5py.File(file_name, 'r') as hf:        \n",
    "        n_slice, n_coil, n_x, n_y = hf['kspace'].shape\n",
    "        if (not n_coil == NUM_LIMIT_COILS) or (n_x < RECON_SIZE[0]) or (n_y < RECON_SIZE[1]) :\n",
    "            continue\n",
    "        if not hf.attrs[\"acquisition\"] == \"AXT2\" :\n",
    "            continue\n",
    "\n",
    "        total_num += 1\n",
    "\n",
    "print(total_num)\n",
    "select_idx = np.random.choice(np.arange(total_num), size = int(total_num * sample_rate) * 2, replace=False)\n",
    "\n",
    "val_select_idx = select_idx[:int(total_num * sample_rate)]\n",
    "test_select_idx = select_idx[int(total_num * sample_rate):]\n",
    "print(len(select_idx))\n",
    "print(select_idx)\n",
    "\n",
    "current_idx = 0\n",
    "for file_idx in tqdm(range(len(glob.glob(SRC + 'file*.h5')))):\n",
    "    file_name = glob.glob(SRC + 'file*.h5')[file_idx]\n",
    "    with h5py.File(file_name, 'r') as hf:        \n",
    "        n_slice, n_coil, n_x, n_y = hf['kspace'].shape\n",
    "        if (not n_coil == NUM_LIMIT_COILS) or (n_x < RECON_SIZE[0]) or (n_y < RECON_SIZE[1]) :\n",
    "            continue\n",
    "        if not hf.attrs[\"acquisition\"] == \"AXT2\" :\n",
    "            continue\n",
    "\n",
    "        kspace = fastmri.fft2c(\n",
    "            complex_center_crop(fastmri.ifft2c(to_tensor(hf['kspace'][()])), RECON_SIZE)\n",
    "        ).numpy()\n",
    "        \n",
    "        kspace_complex = kspace.view(dtype=np.complex64)[...,0]\n",
    "        kspace_compressed = np.empty_like(kspace_complex)[:,0:NUM_COMPRESSED_COILS,...]\n",
    "        reconstruction_rss = np.zeros(shape=((n_slice,)+RECON_SIZE))\n",
    "        \n",
    "        for i in range(n_slice):\n",
    "            kspace_slice = kspace_complex[i]\n",
    "            \n",
    "            kspace_compressed[i, ...] = kspace_slice\n",
    "            \n",
    "            reconstruction_slice = fastmri.rss(fastmri.complex_abs(fastmri.ifft2c(to_tensor(kspace_slice))), dim=0)\n",
    "            reconstruction_rss[i, ...] = reconstruction_slice\n",
    "            \n",
    "        reconstruction_rss = center_crop(reconstruction_rss, RSS_RECON_SIZE).astype(np.float32)\n",
    "        max_new = reconstruction_rss.max()\n",
    "        norm_new = np.linalg.norm(reconstruction_rss)\n",
    "\n",
    "        if current_idx in val_select_idx :\n",
    "            DST = DST_VAL\n",
    "        elif current_idx in test_select_idx :\n",
    "            DST = DST_TEST\n",
    "        else : \n",
    "            current_idx += 1\n",
    "            continue\n",
    "        \n",
    "        with h5py.File(DST+file_name[len(SRC):], 'w') as hfd:\n",
    "            for key in list(hf.keys()):\n",
    "                if key == 'kspace':\n",
    "                    hfd.create_dataset('kspace',data=kspace_compressed,maxshape=kspace_compressed.shape)\n",
    "                elif key == 'reconstruction_rss':\n",
    "                    hfd.create_dataset('reconstruction_rss',data=reconstruction_rss,maxshape=reconstruction_rss.shape)\n",
    "                else:\n",
    "                    old_data = hf[key][()]\n",
    "                    hfd.create_dataset(key,data=old_data)\n",
    "            global_attrs = dict(hf.attrs)\n",
    "            global_attrs['max'] = max_new\n",
    "            global_attrs['norm'] = norm_new\n",
    "            hfd.attrs.update(global_attrs)\n",
    "            \n",
    "        current_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7855b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fastmri\n",
    "from fastmri.data import transforms\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from typing import Dict, NamedTuple, Optional, Sequence, Tuple, Union\n",
    "from fastmri.data.transforms import to_tensor, center_crop, complex_center_crop\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "RECON_SIZE = (320, 320)\n",
    "RSS_RECON_SIZE = (320, 320)\n",
    "NUM_COMPRESSED_COILS = 16 # 4\n",
    "NUM_LIMIT_COILS = 16\n",
    "assert NUM_COMPRESSED_COILS <= NUM_LIMIT_COILS\n",
    "\n",
    "# whole train dataset\n",
    "\n",
    "SRC = '/mnt/e/nyu_fastmri_brain/multicoil_train/' # directory of NYU fastMRI brain multi-coil train dataset\n",
    "DST = '/mnt/e/nyu_fastmri_brain/multibrain_dataset/multicoil_train/' # directory of compressed train dataset\n",
    "\n",
    "os.makedirs(DST, exist_ok=True)\n",
    "\n",
    "np.random.seed(42)\n",
    "sample_rate = 0.2\n",
    "\n",
    "total_num = 0\n",
    "for file_idx in tqdm(range(len(glob.glob(SRC + 'file*.h5')))):\n",
    "    file_name = glob.glob(SRC + 'file*.h5')[file_idx]\n",
    "    with h5py.File(file_name, 'r') as hf:        \n",
    "        n_slice, n_coil, n_x, n_y = hf['kspace'].shape\n",
    "        if (not n_coil == NUM_LIMIT_COILS) or (n_x < RECON_SIZE[0]) or (n_y < RECON_SIZE[1]) :\n",
    "            continue\n",
    "        if not hf.attrs[\"acquisition\"] == \"AXT2\" :\n",
    "            continue\n",
    "        total_num += 1\n",
    "\n",
    "print(total_num)\n",
    "select_idx = np.random.choice(np.arange(total_num), size = int(total_num * sample_rate), replace=False)\n",
    "print(len(select_idx))\n",
    "print(select_idx)\n",
    "\n",
    "current_idx = 0\n",
    "for file_idx in tqdm(range(len(glob.glob(SRC + 'file*.h5')))):\n",
    "    file_name = glob.glob(SRC + 'file*.h5')[file_idx]\n",
    "    with h5py.File(file_name, 'r') as hf:   \n",
    "        n_slice, n_coil, n_x, n_y = hf['kspace'].shape\n",
    "        if (not n_coil == NUM_LIMIT_COILS) or (n_x < RECON_SIZE[0]) or (n_y < RECON_SIZE[1]) :\n",
    "            continue\n",
    "        if not hf.attrs[\"acquisition\"] == \"AXT2\" :\n",
    "            continue\n",
    "\n",
    "        kspace = fastmri.fft2c(\n",
    "            complex_center_crop(fastmri.ifft2c(to_tensor(hf['kspace'][()])), RECON_SIZE)\n",
    "        ).numpy()\n",
    "        \n",
    "        kspace_complex = kspace.view(dtype=np.complex64)[...,0]\n",
    "        kspace_compressed = np.empty_like(kspace_complex)[:,0:NUM_COMPRESSED_COILS,...]\n",
    "        reconstruction_rss = np.zeros(shape=((n_slice,)+RECON_SIZE))\n",
    "        \n",
    "        for i in range(n_slice):\n",
    "            kspace_slice = kspace_complex[i]\n",
    "            \n",
    "            kspace_compressed[i, ...] = kspace_slice\n",
    "            \n",
    "            reconstruction_slice = fastmri.rss(fastmri.complex_abs(fastmri.ifft2c(to_tensor(kspace_slice))), dim=0)\n",
    "            reconstruction_rss[i, ...] = reconstruction_slice\n",
    "            \n",
    "        reconstruction_rss = center_crop(reconstruction_rss, RSS_RECON_SIZE).astype(np.float32)\n",
    "        max_new = reconstruction_rss.max()\n",
    "        norm_new = np.linalg.norm(reconstruction_rss)\n",
    "\n",
    "        if current_idx in select_idx :\n",
    "            with h5py.File(DST+file_name[len(SRC):], 'w') as hfd:\n",
    "                for key in list(hf.keys()):\n",
    "                    if key == 'kspace':\n",
    "                        hfd.create_dataset('kspace',data=kspace_compressed,maxshape=kspace_compressed.shape)\n",
    "                    elif key == 'reconstruction_rss':\n",
    "                        hfd.create_dataset('reconstruction_rss',data=reconstruction_rss,maxshape=reconstruction_rss.shape)\n",
    "                    else:\n",
    "                        old_data = hf[key][()]\n",
    "                        hfd.create_dataset(key,data=old_data)\n",
    "                global_attrs = dict(hf.attrs)\n",
    "                global_attrs['max'] = max_new\n",
    "                global_attrs['norm'] = norm_new\n",
    "                hfd.attrs.update(global_attrs)\n",
    "            current_idx += 1\n",
    "        else : \n",
    "            current_idx += 1\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adaptive_varnet",
   "language": "python",
   "name": "adaptive_varnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
