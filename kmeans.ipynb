{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kmeans.ipynb\n",
    "\n",
    "This notebook generates k-means++ centroids of HF Bayesian uncertainty (c_j)\n",
    "\n",
    "Please run this code after doing Training / Inference of SR space generation model in [./flow](./flow)\n",
    "\n",
    "This notebook assumes you have a HF Bayesian uncertainty maps of the training set, e.g., in './flow/experiments/train_vmap'.\n",
    "\n",
    "Please modify the path in the code if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './flow/experiments/train_vmap/*.npy' # modify if necessary\n",
    "file_list = sorted(glob.glob(file_path))\n",
    "vmaps = np.stack([np.load(f) for f in file_list])\n",
    "print(vmaps.shape, vmaps.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmaps[:,160-20:160+20,160-20:160+20] = 0 # masking out the LF region\n",
    "vmaps_flatten = (vmaps).reshape(-1,320*320)\n",
    "norms = np.linalg.norm(vmaps_flatten, axis=1)\n",
    "vmaps_fn = vmaps_flatten / norms[:,np.newaxis]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should select the number of candidates J (n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3 # this is J in the paper\n",
    "if n_clusters == 1:\n",
    "    centroids = np.expand_dims( vmaps_fn.mean(axis=0), axis=0)\n",
    "    ms = centroids.reshape(-1,320,320)\n",
    "    plt.imshow(ms[0])\n",
    "else:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=1).fit(vmaps_fn)\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    ms = centroids.reshape(-1,320,320)\n",
    "    fig, axs = plt.subplots(1, ms.shape[0], figsize=(10, 10))\n",
    "    for i in range(len(ms)):\n",
    "        axs[i].imshow(np.log(ms[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to know the population of each clusters, please uncomment the following\n",
    "# print(centroids.shape) # (J, 102400)\n",
    "# print((labels==0).sum(),(labels==1).sum(),(labels==2).sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should define the path of the output (centroids of HF uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_MASKS = './mask'\n",
    "if os.path.isdir(DIR_MASKS) is False: os.mkdir(DIR_MASKS)\n",
    "for i in range(n_clusters):\n",
    "    np.save(DIR_MASKS+'vmap_kmeans_'+str(i+1)+'of'+str(n_clusters)+'.npy',ms[i])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
